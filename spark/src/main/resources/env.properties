# Spark Config
spark.master=
spark.app.name=compute
spark.cores.max=8
spark.executor.memory=1536m
spark.ui.port=4040
spark.driver.memory=512m
spark.driver.port=40400
spark.blockManager.port=40405
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.rdd.compress=true
spark.ui.retainedJobs=20
spark.ui.retainedStages=40
spark.debug.maxToStringFields=60
spark.sql.ui.retainedExecutions=0
spark.executor.extraJavaOptions=-XX:MaxPermSize=256M -XX:MaxMetaspaceSize=256M -Duser.timezone=GMT+08
spark.streaming.ui.retainedBatches=40
spark.sql.shuffle.partitions=8
# Cassandra Config
spark.cassandra.connection.host=${common.cassandra.hosts}
spark.cassandra.connection.keep_alive_ms=60000
spark.cassandra.auth.username=${common.cassandra.username}
spark.cassandra.auth.password=${common.cassandra.password}
cassandra.keyspace=${common.cassandra.keyspace}
# Fiume config
receiver.type=flume
flume.receiver.host=${common.spark.master.ip}
flume.receiver.port=7410
# Zookeeper Config
zk.address=${common.zk.address}
zk.elector.namespace=/dev/compute/elect
zk.elector.enable=false
service.port=7420
monitor.enable=false
# Spring quartz Config
aggregate.cron=5/10 * * * * ?
# scheduler.type support 1min<2 * * * * ?> and 5min<2 0/5 * * * ?>(default)
#scheduler.type=2 * * * * ?
# scheduler.type must 1min the config 1min.aggregate is enabled
#1min.aggregate=false
aggregate.max.retry=3
max.rerun.aggregates=12
#retry.time.list=[]
# cleaner cassandra history data open/close
cleaner.cassandra.status=open
cleaner.cassandra.cron=0 47 4 * * ?
cleaner.count=1000000
cleaner.interval=3000
# redis backup open/close
redis.bachup.status=open
redis.backup.cron=0 0 0 * * ?
# when cassandra factor is 2,output=LOCAL_QUORUM,input=LOCAL_ONE
# when cassandra factor > 2,output=LOCAL_QUORUM,input=LOCAL_QUORUM
#spark.cassandra.output.consistency.level=LOCAL_QUORUM
#spark.cassandra.input.consistency.level=LOCAL_ONE